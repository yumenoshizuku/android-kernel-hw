diff --git a/arch/arm/kernel/calls.S b/arch/arm/kernel/calls.S
index 463ff4a..b30b1fd 100644
--- a/arch/arm/kernel/calls.S
+++ b/arch/arm/kernel/calls.S
@@ -387,6 +387,8 @@
 /* 375 */	CALL(sys_setns)
 		CALL(sys_process_vm_readv)
 		CALL(sys_process_vm_writev)
+/* 378 */       CALL(netlock_acquire)
+/* 379 */       CALL(netlock_release)
 #ifndef syscalls_counted
 .equ syscalls_padding, ((NR_syscalls + 3) & ~3) - NR_syscalls
 #define syscalls_counted
diff --git a/include/linux/sched.h b/include/linux/sched.h
index ff6bb0f..7d12343 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -93,6 +93,15 @@ struct sched_param {
 
 #include <asm/processor.h>
 
+enum __netlock_t 
+{
+	NET_LOCK_N, /* Placeholder for no lock */
+	NET_LOCK_R, /* Indicates regular lock */
+	NET_LOCK_E, /* Indicates exclusive lock */
+};
+
+typedef enum __netlock_t netlock_t;
+
 struct exec_domain;
 struct futex_pi_state;
 struct robust_list_head;
@@ -1619,6 +1628,7 @@ struct task_struct {
 #ifdef CONFIG_HAVE_HW_BREAKPOINT
 	atomic_t ptrace_bp_refcnt;
 #endif
+	netlock_t lock_type;
 };
 
 /* Future-safe accessor for struct task_struct's cpus_allowed. */
diff --git a/include/linux/syscalls.h b/include/linux/syscalls.h
index 3de3acb..2090043 100644
--- a/include/linux/syscalls.h
+++ b/include/linux/syscalls.h
@@ -858,4 +858,7 @@ asmlinkage long sys_process_vm_writev(pid_t pid,
 				      unsigned long riovcnt,
 				      unsigned long flags);
 
+asmlinkage int netlock_acquire(netlock_t type);
+asmlinkage int netlock_release(void);
+
 #endif
diff --git a/kernel/Makefile b/kernel/Makefile
index cb41b95..85630e7 100644
--- a/kernel/Makefile
+++ b/kernel/Makefile
@@ -10,7 +10,7 @@ obj-y     = fork.o exec_domain.o panic.o printk.o \
 	    kthread.o wait.o kfifo.o sys_ni.o posix-cpu-timers.o mutex.o \
 	    hrtimer.o rwsem.o nsproxy.o srcu.o semaphore.o \
 	    notifier.o ksysfs.o cred.o \
-	    async.o range.o groups.o
+	    async.o range.o groups.o netlock.o
 
 ifdef CONFIG_FUNCTION_TRACER
 # Do not trace debug files and internal ftrace files
diff --git a/kernel/fork.c b/kernel/fork.c
index 0de735c..71319ab 100644
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -1222,6 +1222,7 @@ static struct task_struct *copy_process(unsigned long clone_flags,
 	INIT_LIST_HEAD(&p->sibling);
 	rcu_copy_process(p);
 	p->vfork_done = NULL;
+	p->lock_type = NET_LOCK_N;
 	spin_lock_init(&p->alloc_lock);
 
 	init_sigpending(&p->pending);
diff --git a/kernel/netlock.c b/kernel/netlock.c
new file mode 100644
index 0000000..2d5908a
--- /dev/null
+++ b/kernel/netlock.c
@@ -0,0 +1,140 @@
+#include <linux/syscalls.h>
+#include <linux/list.h>
+#include <linux/wait.h>
+#include <linux/spinlock.h>
+
+#define NETLOCK_SUCCESS 0
+#define NETLOCK_FAILURE -1
+
+struct __netlock_lock_t
+{ 
+	int reader_count;
+	netlock_t lock;
+};
+
+/* File scope variables */
+static struct __netlock_lock_t netlock = { .reader_count = 0, .lock = NET_LOCK_N };
+static DEFINE_SPINLOCK(net_spinlock);
+static DECLARE_WAIT_QUEUE_HEAD(reader_queue);
+static DECLARE_WAIT_QUEUE_HEAD(writer_queue);
+
+/* 
+   Syscall 378. Acquire netlock. 
+   Type indicates whether a regular or exclusive lock is needed. 
+   Returns 0 on success and -1 on failure.  
+*/
+asmlinkage int netlock_acquire(netlock_t type)
+{
+	int ret_value = NETLOCK_FAILURE;
+
+	if( current->lock_type != NET_LOCK_N )
+	{
+		// What to do here? - asked on piazza
+		// I'm assuming its not allowed
+	}
+	else if( type == NET_LOCK_E && 
+		 netlock.lock != NET_LOCK_E &&
+	    	 netlock.reader_count == 0 )
+	{
+		spin_lock( &net_spinlock );
+		current->lock_type = type;
+		netlock.lock = NET_LOCK_E;
+		spin_unlock( &net_spinlock );
+
+		ret_value = NETLOCK_SUCCESS;
+	}
+	else if( type == NET_LOCK_E )
+	{
+		__wait_event_interruptible_exclusive( writer_queue, 
+   					              netlock.lock != NET_LOCK_E && 
+	    	 					netlock.reader_count == 0, 
+						      ret_value );	
+		if( netlock.reader_count == 0 )
+		{
+			spin_lock( &net_spinlock );
+			current->lock_type = type;
+			netlock.lock = NET_LOCK_E;
+			spin_unlock( &net_spinlock );
+		
+			ret_value = NETLOCK_SUCCESS;	
+		}
+	}
+	else if( type == NET_LOCK_R && 
+		 netlock.lock != NET_LOCK_E && 
+		 list_empty(&writer_queue.task_list) )
+	{
+		spin_lock( &net_spinlock );
+		current->lock_type = type;
+		++netlock.reader_count;
+		spin_unlock( &net_spinlock );
+
+		ret_value = NETLOCK_SUCCESS;
+	}
+	else if( type == NET_LOCK_R )
+	{
+		__wait_event_interruptible_exclusive( reader_queue, 
+   					              netlock.lock != NET_LOCK_E && 
+							list_empty(&writer_queue.task_list), 
+						      ret_value );
+
+		if( netlock.lock != NET_LOCK_E && list_empty(&writer_queue.task_list) )
+		{
+			spin_lock( &net_spinlock );
+			current->lock_type = type;
+			++netlock.reader_count;
+			spin_unlock( &net_spinlock );
+
+			ret_value = NETLOCK_SUCCESS;
+		}
+	}
+	
+	return ret_value;
+}
+
+/* 
+   Syscall 379. Release netlock. 
+   Return 0 on success and -1 on failure.  
+*/
+asmlinkage int netlock_release(void)
+{
+	int ret_value = NETLOCK_FAILURE;
+
+	if( current->lock_type == NET_LOCK_R )
+	{
+		spin_lock( &net_spinlock );
+		--netlock.reader_count;
+		current->lock_type = NET_LOCK_N;
+		spin_unlock( &net_spinlock );
+
+		if( !list_empty(&writer_queue.task_list) )
+		{
+			wake_up_interruptible( &writer_queue );
+		}
+		else
+		{
+			wake_up_interruptible( &reader_queue );
+		}
+					
+		ret_value = NETLOCK_SUCCESS;
+	}
+	else if( current->lock_type == NET_LOCK_E )
+	{
+		spin_lock( &net_spinlock );
+		netlock.lock = NET_LOCK_N;
+		current->lock_type = NET_LOCK_N;
+		spin_unlock( &net_spinlock );
+		
+		if( !list_empty(&writer_queue.task_list) )
+		{
+			wake_up_interruptible( &writer_queue );
+		}
+		else
+		{
+			wake_up_interruptible( &reader_queue );
+		}		
+		
+		ret_value = NETLOCK_SUCCESS;
+	}
+	
+	return ret_value;	
+}
